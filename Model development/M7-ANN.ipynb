{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "%matplotlib inline\n",
    "import  matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>V</th>\n",
       "      <th>DO</th>\n",
       "      <th>E</th>\n",
       "      <th>pH</th>\n",
       "      <th>TOC</th>\n",
       "      <th>TN</th>\n",
       "      <th>C/N</th>\n",
       "      <th>C/S</th>\n",
       "      <th>SO4</th>\n",
       "      <th>H2S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.397959</td>\n",
       "      <td>0.227172</td>\n",
       "      <td>0.979195</td>\n",
       "      <td>961.551020</td>\n",
       "      <td>7.345535</td>\n",
       "      <td>36.519993</td>\n",
       "      <td>16.075040</td>\n",
       "      <td>2.301271</td>\n",
       "      <td>0.607562</td>\n",
       "      <td>61.503898</td>\n",
       "      <td>17.966688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.303798</td>\n",
       "      <td>0.090988</td>\n",
       "      <td>0.640229</td>\n",
       "      <td>75.694341</td>\n",
       "      <td>0.094923</td>\n",
       "      <td>21.429253</td>\n",
       "      <td>5.540479</td>\n",
       "      <td>1.007613</td>\n",
       "      <td>0.383239</td>\n",
       "      <td>13.442816</td>\n",
       "      <td>17.429645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>745.000000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>8.568129</td>\n",
       "      <td>6.243985</td>\n",
       "      <td>0.941765</td>\n",
       "      <td>0.225891</td>\n",
       "      <td>35.936300</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.158986</td>\n",
       "      <td>0.359371</td>\n",
       "      <td>920.750000</td>\n",
       "      <td>7.280826</td>\n",
       "      <td>21.641416</td>\n",
       "      <td>11.899717</td>\n",
       "      <td>1.473589</td>\n",
       "      <td>0.355115</td>\n",
       "      <td>50.422000</td>\n",
       "      <td>2.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>1.031873</td>\n",
       "      <td>972.000000</td>\n",
       "      <td>7.320000</td>\n",
       "      <td>32.172224</td>\n",
       "      <td>15.787898</td>\n",
       "      <td>2.077881</td>\n",
       "      <td>0.502995</td>\n",
       "      <td>61.367400</td>\n",
       "      <td>9.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>1.465000</td>\n",
       "      <td>1018.250000</td>\n",
       "      <td>7.380000</td>\n",
       "      <td>46.386019</td>\n",
       "      <td>19.151969</td>\n",
       "      <td>2.998457</td>\n",
       "      <td>0.768295</td>\n",
       "      <td>69.168200</td>\n",
       "      <td>34.592805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.558000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>155.442607</td>\n",
       "      <td>40.117917</td>\n",
       "      <td>5.704046</td>\n",
       "      <td>3.945414</td>\n",
       "      <td>98.179500</td>\n",
       "      <td>51.572163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                L           V          DO            E          pH  \\\n",
       "count  196.000000  196.000000  196.000000   196.000000  196.000000   \n",
       "mean     5.397959    0.227172    0.979195   961.551020    7.345535   \n",
       "std      2.303798    0.090988    0.640229    75.694341    0.094923   \n",
       "min      1.000000    0.102000    0.020000   745.000000    7.100000   \n",
       "25%      3.750000    0.158986    0.359371   920.750000    7.280826   \n",
       "50%      6.000000    0.209000    1.031873   972.000000    7.320000   \n",
       "75%      7.000000    0.275000    1.465000  1018.250000    7.380000   \n",
       "max      9.000000    0.558000    2.540000  1100.000000    7.700000   \n",
       "\n",
       "              TOC          TN         C/N         C/S         SO4         H2S  \n",
       "count  196.000000  196.000000  196.000000  196.000000  196.000000  196.000000  \n",
       "mean    36.519993   16.075040    2.301271    0.607562   61.503898   17.966688  \n",
       "std     21.429253    5.540479    1.007613    0.383239   13.442816   17.429645  \n",
       "min      8.568129    6.243985    0.941765    0.225891   35.936300    0.010000  \n",
       "25%     21.641416   11.899717    1.473589    0.355115   50.422000    2.862500  \n",
       "50%     32.172224   15.787898    2.077881    0.502995   61.367400    9.710000  \n",
       "75%     46.386019   19.151969    2.998457    0.768295   69.168200   34.592805  \n",
       "max    155.442607   40.117917    5.704046    3.945414   98.179500   51.572163  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv(\"C:/Users/Van/11H2S/Different Model-new/train_com.csv\")\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>V</th>\n",
       "      <th>DO</th>\n",
       "      <th>E</th>\n",
       "      <th>pH</th>\n",
       "      <th>TOC</th>\n",
       "      <th>TN</th>\n",
       "      <th>C/N</th>\n",
       "      <th>C/S</th>\n",
       "      <th>SO4</th>\n",
       "      <th>H2S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.791667</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>1.114167</td>\n",
       "      <td>954.000000</td>\n",
       "      <td>7.356667</td>\n",
       "      <td>33.082966</td>\n",
       "      <td>16.421136</td>\n",
       "      <td>2.065140</td>\n",
       "      <td>0.538394</td>\n",
       "      <td>63.681004</td>\n",
       "      <td>30.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.264646</td>\n",
       "      <td>0.074305</td>\n",
       "      <td>0.661999</td>\n",
       "      <td>83.173993</td>\n",
       "      <td>0.107851</td>\n",
       "      <td>17.205562</td>\n",
       "      <td>6.707066</td>\n",
       "      <td>0.855174</td>\n",
       "      <td>0.304127</td>\n",
       "      <td>13.195245</td>\n",
       "      <td>17.598888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>807.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>9.727586</td>\n",
       "      <td>5.973685</td>\n",
       "      <td>0.931152</td>\n",
       "      <td>0.166123</td>\n",
       "      <td>36.481900</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.139250</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>895.000000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>21.539393</td>\n",
       "      <td>12.769102</td>\n",
       "      <td>1.383196</td>\n",
       "      <td>0.326058</td>\n",
       "      <td>59.029075</td>\n",
       "      <td>15.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>7.320000</td>\n",
       "      <td>28.351351</td>\n",
       "      <td>15.669401</td>\n",
       "      <td>2.012730</td>\n",
       "      <td>0.472753</td>\n",
       "      <td>64.461800</td>\n",
       "      <td>33.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.235750</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1006.750000</td>\n",
       "      <td>7.440000</td>\n",
       "      <td>45.563246</td>\n",
       "      <td>18.390176</td>\n",
       "      <td>2.669494</td>\n",
       "      <td>0.721353</td>\n",
       "      <td>69.482000</td>\n",
       "      <td>46.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1074.000000</td>\n",
       "      <td>7.610000</td>\n",
       "      <td>84.636852</td>\n",
       "      <td>40.117917</td>\n",
       "      <td>4.231449</td>\n",
       "      <td>1.420067</td>\n",
       "      <td>98.179500</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               L          V         DO            E         pH        TOC  \\\n",
       "count  24.000000  24.000000  24.000000    24.000000  24.000000  24.000000   \n",
       "mean    5.791667   0.195000   1.114167   954.000000   7.356667  33.082966   \n",
       "std     2.264646   0.074305   0.661999    83.173993   0.107851  17.205562   \n",
       "min     1.000000   0.102000   0.120000   807.000000   7.200000   9.727586   \n",
       "25%     6.000000   0.139250   0.390000   895.000000   7.270000  21.539393   \n",
       "50%     7.000000   0.166000   1.250000   960.000000   7.320000  28.351351   \n",
       "75%     7.000000   0.235750   1.650000  1006.750000   7.440000  45.563246   \n",
       "max     9.000000   0.351000   2.250000  1074.000000   7.610000  84.636852   \n",
       "\n",
       "              TN        C/N        C/S        SO4        H2S  \n",
       "count  24.000000  24.000000  24.000000  24.000000  24.000000  \n",
       "mean   16.421136   2.065140   0.538394  63.681004  30.175000  \n",
       "std     6.707066   0.855174   0.304127  13.195245  17.598888  \n",
       "min     5.973685   0.931152   0.166123  36.481900   0.010000  \n",
       "25%    12.769102   1.383196   0.326058  59.029075  15.787500  \n",
       "50%    15.669401   2.012730   0.472753  64.461800  33.250000  \n",
       "75%    18.390176   2.669494   0.721353  69.482000  46.580000  \n",
       "max    40.117917   4.231449   1.420067  98.179500  50.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(\"../test1.csv\")\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=np.array(train)\n",
    "test=np.array(test)\n",
    "x_train = train[:,:10]\n",
    "y_train =train[:,10]\n",
    "x_test = test[:,:10]\n",
    "y_test = test[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler1=MinMaxScaler()\n",
    "scaler2=MinMaxScaler()\n",
    "scaler3=MinMaxScaler()\n",
    "scaler4=MinMaxScaler()\n",
    "\n",
    "x_train_ts=scaler1.fit_transform(x_train)\n",
    "y_train_ts=scaler2.fit_transform(np.reshape(y_train,(-1,1)))\n",
    "x_test_ts=scaler3.fit_transform(x_test)\n",
    "y_test_ts=scaler4.fit_transform(np.reshape(y_test,(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(x_train_ts, y_train_ts, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 156 samples, validate on 40 samples\n",
      "Epoch 1/100\n",
      "156/156 [==============================] - 1s 4ms/sample - loss: 0.1941 - val_loss: 0.0934\n",
      "Epoch 2/100\n",
      "156/156 [==============================] - 0s 77us/sample - loss: 0.1191 - val_loss: 0.0861\n",
      "Epoch 3/100\n",
      "156/156 [==============================] - 0s 41us/sample - loss: 0.0973 - val_loss: 0.0770\n",
      "Epoch 4/100\n",
      "156/156 [==============================] - 0s 113us/sample - loss: 0.0896 - val_loss: 0.0648\n",
      "Epoch 5/100\n",
      "156/156 [==============================] - 0s 72us/sample - loss: 0.0751 - val_loss: 0.0490\n",
      "Epoch 6/100\n",
      "156/156 [==============================] - 0s 71us/sample - loss: 0.0648 - val_loss: 0.0426\n",
      "Epoch 7/100\n",
      "156/156 [==============================] - 0s 68us/sample - loss: 0.0590 - val_loss: 0.0388\n",
      "Epoch 8/100\n",
      "156/156 [==============================] - 0s 72us/sample - loss: 0.0515 - val_loss: 0.0345\n",
      "Epoch 9/100\n",
      "156/156 [==============================] - 0s 73us/sample - loss: 0.0468 - val_loss: 0.0312\n",
      "Epoch 10/100\n",
      "156/156 [==============================] - 0s 44us/sample - loss: 0.0417 - val_loss: 0.0285\n",
      "Epoch 11/100\n",
      "156/156 [==============================] - 0s 96us/sample - loss: 0.0358 - val_loss: 0.0243\n",
      "Epoch 12/100\n",
      "156/156 [==============================] - 0s 75us/sample - loss: 0.0313 - val_loss: 0.0218\n",
      "Epoch 13/100\n",
      "156/156 [==============================] - 0s 43us/sample - loss: 0.0278 - val_loss: 0.0250\n",
      "Epoch 14/100\n",
      "156/156 [==============================] - 0s 100us/sample - loss: 0.0256 - val_loss: 0.0196\n",
      "Epoch 15/100\n",
      "156/156 [==============================] - 0s 0s/sample - loss: 0.0190 - val_loss: 0.0159\n",
      "Epoch 16/100\n",
      "156/156 [==============================] - 0s 109us/sample - loss: 0.0146 - val_loss: 0.0159\n",
      "Epoch 17/100\n",
      "156/156 [==============================] - 0s 93us/sample - loss: 0.0162 - val_loss: 0.0129\n",
      "Epoch 18/100\n",
      "156/156 [==============================] - 0s 0s/sample - loss: 0.0146 - val_loss: 0.0128\n",
      "Epoch 19/100\n",
      "156/156 [==============================] - 0s 100us/sample - loss: 0.0114 - val_loss: 0.0127\n",
      "Epoch 20/100\n",
      "156/156 [==============================] - 0s 102us/sample - loss: 0.0110 - val_loss: 0.0137\n",
      "Epoch 21/100\n",
      "156/156 [==============================] - 0s 105us/sample - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 22/100\n",
      "156/156 [==============================] - 0s 64us/sample - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 23/100\n",
      "156/156 [==============================] - 0s 3us/sample - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 24/100\n",
      "156/156 [==============================] - 0s 100us/sample - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 25/100\n",
      "156/156 [==============================] - 0s 122us/sample - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 26/100\n",
      "156/156 [==============================] - 0s 45us/sample - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 27/100\n",
      "156/156 [==============================] - 0s 112us/sample - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 28/100\n",
      "156/156 [==============================] - 0s 105us/sample - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 29/100\n",
      "156/156 [==============================] - 0s 45us/sample - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 30/100\n",
      "156/156 [==============================] - 0s 96us/sample - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 31/100\n",
      "156/156 [==============================] - 0s 108us/sample - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 32/100\n",
      "156/156 [==============================] - 0s 56us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 33/100\n",
      "156/156 [==============================] - 0s 91us/sample - loss: 9.9951e-04 - val_loss: 0.0033\n",
      "Epoch 34/100\n",
      "156/156 [==============================] - 0s 77us/sample - loss: 9.1063e-04 - val_loss: 0.0028\n",
      "Epoch 35/100\n",
      "156/156 [==============================] - 0s 93us/sample - loss: 7.7541e-04 - val_loss: 0.0026\n",
      "Epoch 36/100\n",
      "156/156 [==============================] - 0s 109us/sample - loss: 7.5777e-04 - val_loss: 0.0025\n",
      "Epoch 37/100\n",
      "156/156 [==============================] - 0s 80us/sample - loss: 8.0884e-04 - val_loss: 0.0025\n",
      "Epoch 38/100\n",
      "156/156 [==============================] - 0s 101us/sample - loss: 6.2502e-04 - val_loss: 0.0026\n",
      "Epoch 39/100\n",
      "156/156 [==============================] - 0s 95us/sample - loss: 7.9863e-04 - val_loss: 0.0040\n",
      "Epoch 40/100\n",
      "156/156 [==============================] - 0s 92us/sample - loss: 0.0010 - val_loss: 0.0024\n",
      "Epoch 41/100\n",
      "156/156 [==============================] - 0s 91us/sample - loss: 7.6758e-04 - val_loss: 0.0027\n",
      "Epoch 42/100\n",
      "156/156 [==============================] - 0s 105us/sample - loss: 7.6213e-04 - val_loss: 0.0028\n",
      "Epoch 43/100\n",
      "156/156 [==============================] - 0s 99us/sample - loss: 5.9200e-04 - val_loss: 0.0032\n",
      "Epoch 44/100\n",
      "156/156 [==============================] - 0s 99us/sample - loss: 8.1308e-04 - val_loss: 0.0024\n",
      "Epoch 45/100\n",
      "156/156 [==============================] - 0s 85us/sample - loss: 7.6395e-04 - val_loss: 0.0030\n",
      "Epoch 46/100\n",
      "156/156 [==============================] - 0s 84us/sample - loss: 9.7881e-04 - val_loss: 0.0025\n",
      "Epoch 47/100\n",
      "156/156 [==============================] - 0s 76us/sample - loss: 7.8507e-04 - val_loss: 0.0024\n",
      "Epoch 48/100\n",
      "156/156 [==============================] - 0s 79us/sample - loss: 7.4641e-04 - val_loss: 0.0048\n",
      "Epoch 49/100\n",
      "156/156 [==============================] - 0s 79us/sample - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 50/100\n",
      "156/156 [==============================] - 0s 72us/sample - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 51/100\n",
      "156/156 [==============================] - 0s 35us/sample - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 52/100\n",
      "156/156 [==============================] - 0s 119us/sample - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 53/100\n",
      "156/156 [==============================] - 0s 73us/sample - loss: 9.8330e-04 - val_loss: 0.0040\n",
      "Epoch 54/100\n",
      "156/156 [==============================] - 0s 70us/sample - loss: 9.0033e-04 - val_loss: 0.0016\n",
      "Epoch 55/100\n",
      "156/156 [==============================] - 0s 73us/sample - loss: 4.9625e-04 - val_loss: 0.0022\n",
      "Epoch 56/100\n",
      "156/156 [==============================] - 0s 73us/sample - loss: 7.9139e-04 - val_loss: 0.0020\n",
      "Epoch 57/100\n",
      "156/156 [==============================] - 0s 65us/sample - loss: 4.9476e-04 - val_loss: 0.0028\n",
      "Epoch 58/100\n",
      "156/156 [==============================] - 0s 34us/sample - loss: 4.5261e-04 - val_loss: 0.0023\n",
      "Epoch 59/100\n",
      "156/156 [==============================] - 0s 113us/sample - loss: 3.1409e-04 - val_loss: 0.0022\n",
      "Epoch 60/100\n",
      "156/156 [==============================] - 0s 73us/sample - loss: 4.0636e-04 - val_loss: 0.0026\n",
      "Epoch 61/100\n",
      "156/156 [==============================] - 0s 73us/sample - loss: 4.3881e-04 - val_loss: 0.0030\n",
      "Epoch 62/100\n",
      "156/156 [==============================] - 0s 74us/sample - loss: 4.6864e-04 - val_loss: 0.0022\n",
      "Epoch 63/100\n",
      "156/156 [==============================] - 0s 71us/sample - loss: 2.8555e-04 - val_loss: 0.0023\n",
      "Epoch 64/100\n",
      "156/156 [==============================] - 0s 64us/sample - loss: 4.0730e-04 - val_loss: 0.0026\n",
      "Epoch 65/100\n",
      "156/156 [==============================] - 0s 0s/sample - loss: 2.8458e-04 - val_loss: 0.0022\n",
      "Epoch 66/100\n",
      "156/156 [==============================] - 0s 96us/sample - loss: 2.1218e-04 - val_loss: 0.0023\n",
      "Epoch 67/100\n",
      "156/156 [==============================] - 0s 101us/sample - loss: 1.8842e-04 - val_loss: 0.0023\n",
      "Epoch 68/100\n",
      "156/156 [==============================] - 0s 0s/sample - loss: 1.4137e-04 - val_loss: 0.0021\n",
      "Epoch 69/100\n",
      "156/156 [==============================] - 0s 0s/sample - loss: 1.9194e-04 - val_loss: 0.0020\n",
      "Epoch 70/100\n",
      "156/156 [==============================] - 0s 100us/sample - loss: 1.9468e-04 - val_loss: 0.0028\n",
      "Epoch 71/100\n",
      "156/156 [==============================] - 0s 103us/sample - loss: 3.3618e-04 - val_loss: 0.0027\n",
      "Epoch 72/100\n",
      "156/156 [==============================] - 0s 0s/sample - loss: 2.5399e-04 - val_loss: 0.0022\n",
      "Epoch 73/100\n",
      "156/156 [==============================] - 0s 100us/sample - loss: 2.7741e-04 - val_loss: 0.0022\n",
      "Epoch 74/100\n",
      "156/156 [==============================] - 0s 100us/sample - loss: 1.9420e-04 - val_loss: 0.0022\n",
      "Epoch 75/100\n",
      "156/156 [==============================] - 0s 0s/sample - loss: 1.9117e-04 - val_loss: 0.0021\n",
      "Epoch 76/100\n",
      "156/156 [==============================] - 0s 100us/sample - loss: 2.2270e-04 - val_loss: 0.0021\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 101us/sample - loss: 1.5414e-04 - val_loss: 0.0021\n",
      "Epoch 78/100\n",
      "156/156 [==============================] - 0s 100us/sample - loss: 1.4012e-04 - val_loss: 0.0024\n",
      "Epoch 79/100\n",
      "156/156 [==============================] - 0s 0s/sample - loss: 1.4151e-04 - val_loss: 0.0021\n",
      "Epoch 80/100\n",
      "156/156 [==============================] - 0s 124us/sample - loss: 9.9845e-05 - val_loss: 0.0021\n",
      "Epoch 81/100\n",
      "156/156 [==============================] - 0s 101us/sample - loss: 1.4926e-04 - val_loss: 0.0028\n",
      "Epoch 82/100\n",
      "156/156 [==============================] - 0s 65us/sample - loss: 2.5809e-04 - val_loss: 0.0024\n",
      "Epoch 83/100\n",
      "156/156 [==============================] - 0s 32us/sample - loss: 2.2916e-04 - val_loss: 0.0022\n",
      "Epoch 84/100\n",
      "156/156 [==============================] - 0s 101us/sample - loss: 2.7629e-04 - val_loss: 0.0025\n",
      "Epoch 85/100\n",
      "156/156 [==============================] - 0s 0s/sample - loss: 3.3641e-04 - val_loss: 0.0024\n",
      "Epoch 86/100\n",
      "156/156 [==============================] - 0s 100us/sample - loss: 3.0806e-04 - val_loss: 0.0024\n",
      "Epoch 87/100\n",
      "156/156 [==============================] - 0s 128us/sample - loss: 2.2483e-04 - val_loss: 0.0028\n",
      "Epoch 88/100\n",
      "156/156 [==============================] - 0s 87us/sample - loss: 1.8979e-04 - val_loss: 0.0024\n",
      "Epoch 89/100\n",
      "156/156 [==============================] - 0s 70us/sample - loss: 3.1452e-04 - val_loss: 0.0022\n",
      "Epoch 90/100\n",
      "156/156 [==============================] - 0s 118us/sample - loss: 3.8594e-04 - val_loss: 0.0020\n",
      "Epoch 91/100\n",
      "156/156 [==============================] - 0s 78us/sample - loss: 4.6803e-04 - val_loss: 0.0025\n",
      "Epoch 92/100\n",
      "156/156 [==============================] - 0s 50us/sample - loss: 4.9062e-04 - val_loss: 0.0020\n",
      "Epoch 93/100\n",
      "156/156 [==============================] - 0s 105us/sample - loss: 4.9947e-04 - val_loss: 0.0027\n",
      "Epoch 94/100\n",
      "156/156 [==============================] - 0s 52us/sample - loss: 2.6807e-04 - val_loss: 0.0028\n",
      "Epoch 95/100\n",
      "156/156 [==============================] - 0s 108us/sample - loss: 3.4016e-04 - val_loss: 0.0027\n",
      "Epoch 96/100\n",
      "156/156 [==============================] - 0s 81us/sample - loss: 4.5956e-04 - val_loss: 0.0025\n",
      "Epoch 97/100\n",
      "156/156 [==============================] - 0s 79us/sample - loss: 1.9889e-04 - val_loss: 0.0024\n",
      "Epoch 98/100\n",
      "156/156 [==============================] - 0s 79us/sample - loss: 2.1479e-04 - val_loss: 0.0022\n",
      "Epoch 99/100\n",
      "156/156 [==============================] - 0s 77us/sample - loss: 2.2034e-04 - val_loss: 0.0022\n",
      "Epoch 100/100\n",
      "156/156 [==============================] - 0s 79us/sample - loss: 2.5198e-04 - val_loss: 0.0023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27846419c88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 创建神经网络模型\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(10,)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),    \n",
    "    keras.layers.Dense(128, activation='relu'),    \n",
    "    keras.layers.Dense(128, activation='relu'),    \n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(1)  # 输出层，1个神经元，用于回归任务\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1) (24,)\n"
     ]
    }
   ],
   "source": [
    "pre1=model.predict(x_test_ts)\n",
    "pre=scaler4.inverse_transform(pre1)\n",
    "print(pre.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.53279436]\n",
      " [ 4.427556  ]\n",
      " [ 2.700931  ]\n",
      " [ 2.6529424 ]\n",
      " [18.382998  ]\n",
      " [ 2.583586  ]\n",
      " [ 1.7555788 ]\n",
      " [40.229378  ]\n",
      " [21.031261  ]\n",
      " [47.28637   ]\n",
      " [35.110252  ]\n",
      " [36.657673  ]\n",
      " [21.0966    ]\n",
      " [26.780172  ]\n",
      " [-0.22880568]\n",
      " [24.152294  ]\n",
      " [25.108217  ]\n",
      " [40.103172  ]\n",
      " [22.351223  ]\n",
      " [27.483503  ]\n",
      " [32.328094  ]\n",
      " [36.323895  ]\n",
      " [40.229378  ]\n",
      " [47.28637   ]] [1.000e-02 1.000e-02 2.490e+00 2.630e+00 1.410e+01 1.548e+01 1.589e+01\n",
      " 5.000e+01 5.000e+01 5.000e+01 3.812e+01 4.140e+01 2.218e+01 2.329e+01\n",
      " 2.859e+01 2.969e+01 3.284e+01 3.366e+01 3.573e+01 4.265e+01 4.544e+01\n",
      " 5.000e+01 5.000e+01 5.000e+01]\n"
     ]
    }
   ],
   "source": [
    "print(pre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error: 0.1722141957240354\n",
      "mean_squared_error: 0.053762873866587596\n",
      "rmse: 0.2318682252198166\n",
      "r2 score: 0.5473508752546676\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "MAE=mean_absolute_error(y_test_ts, pre1)\n",
    "MSE=mean_squared_error(y_test_ts, pre1)\n",
    "RMSE=sqrt(mean_squared_error(y_test_ts,pre1))\n",
    "R2=r2_score(y_test_ts,pre1)\n",
    "print(\"mean_absolute_error:\", mean_absolute_error( pre1,y_test_ts))\n",
    "print(\"mean_squared_error:\", mean_squared_error(y_test_ts, pre1))\n",
    "print(\"rmse:\", sqrt(mean_squared_error(y_test_ts,pre1)))\n",
    "print(\"r2 score:\", r2_score(y_test_ts,pre1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error: 8.608987493738532\n",
      "mean_squared_error: 134.35342853988652\n",
      "rmse: 11.591092637878731\n",
      "r2 score: 0.5473508706356528\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "MAE=mean_absolute_error(y_test, pre)\n",
    "MSE=mean_squared_error(y_test, pre)\n",
    "RMSE=sqrt(mean_squared_error(y_test,pre))\n",
    "R2=r2_score(y_test,pre)\n",
    "print(\"mean_absolute_error:\", mean_absolute_error( pre,y_test))\n",
    "print(\"mean_squared_error:\", mean_squared_error(y_test, pre))\n",
    "print(\"rmse:\", sqrt(mean_squared_error(y_test,pre)))\n",
    "print(\"r2 score:\", r2_score(y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Metric       Value\n",
      "0  mean_absolute_error    8.608987\n",
      "1   mean_squared_error  134.353429\n",
      "2                 rmse   11.591093\n",
      "3             r2 score    0.547351\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    'Metric': ['mean_absolute_error', 'mean_squared_error', 'rmse', 'r2 score'],\n",
    "    'Value': [MAE, MSE, RMSE, R2]\n",
    "}\n",
    "# 使用Pandas创建一个数据框\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 打印数据框\n",
    "print(results_df)\n",
    "results_df.to_csv('1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapre=np.asarray(pre)\n",
    "datapre.tofile('1-pre.csv',sep=',',format='%10.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.6",
   "language": "python",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
